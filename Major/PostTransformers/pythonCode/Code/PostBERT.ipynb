{"cells":[{"cell_type":"markdown","metadata":{"id":"cFEpHz9q2TkF"},"source":["# PostBERT\n","- https://github.com/monologg/KoBERT-Transformers\n","- https://github.com/SKTBrain/KoBERT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VPmd3h1VZUs8"},"outputs":[],"source":["##Parameter setting\n","setEpoch = 51\n","setLearningRate = 0.00002\n","setEpsilon = 1e-8\n","setBatch = 16\n","setMaxLength = 128\n","setSeed = 42\n","setTry = 3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19168,"status":"ok","timestamp":1640859346068,"user":{"displayName":"Seongmin Mun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxXPWH0f2f0ThPPwM2evOCWKaCSlwmGiaeEFSK=s64","userId":"17295717412647902050"},"user_tz":-540},"id":"9LAZ1CSc3Bm_","outputId":"976880ae-5efb-4438-dbeb-247a1dccb937"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}],"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')\n","    \n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18035,"status":"ok","timestamp":1640859438733,"user":{"displayName":"Seongmin Mun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxXPWH0f2f0ThPPwM2evOCWKaCSlwmGiaeEFSK=s64","userId":"17295717412647902050"},"user_tz":-540},"id":"SEAoJWbt2TkL","outputId":"1c6560f6-9f90-4f29-bdbd-dd3536d3b315"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 4.1 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 649 kB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 64.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 88.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 68.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n","Collecting kobert_transformers\n","  Downloading kobert_transformers-0.5.1-py3-none-any.whl (12 kB)\n","Collecting sentencepiece>=0.1.91\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from kobert_transformers) (1.10.0+cu111)\n","Requirement already satisfied: transformers<5,>=3 in /usr/local/lib/python3.7/dist-packages (from kobert_transformers) (4.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->kobert_transformers) (3.10.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert_transformers) (3.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert_transformers) (4.62.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert_transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert_transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert_transformers) (0.0.46)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert_transformers) (4.8.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert_transformers) (2019.12.20)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert_transformers) (0.2.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert_transformers) (0.10.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert_transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert_transformers) (1.19.5)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5,>=3->kobert_transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5,>=3->kobert_transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert_transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert_transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert_transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert_transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=3->kobert_transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=3->kobert_transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=3->kobert_transformers) (1.15.0)\n","Installing collected packages: sentencepiece, kobert-transformers\n","Successfully installed kobert-transformers-0.5.1 sentencepiece-0.1.96\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}],"source":["!pip install transformers\n","!pip install kobert_transformers\n","!pip install tensorflow\n","!pip install keras\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hv2_wH8A2TkN"},"outputs":[],"source":["import tensorflow as tf\n","import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime\n","import sentencepiece as spm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21090,"status":"ok","timestamp":1640859469405,"user":{"displayName":"Seongmin Mun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxXPWH0f2f0ThPPwM2evOCWKaCSlwmGiaeEFSK=s64","userId":"17295717412647902050"},"user_tz":-540},"id":"X3aCo4t22ahB","outputId":"a691162c-aeef-4d69-df8c-b039c5243512"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive to this Notebook instance.\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-Ua-ci84w0f"},"outputs":[],"source":["# coding=utf-8\n","# Copyright 2018 Google AI, Google Brain and Carnegie Mellon University Authors and the HuggingFace Inc. team and Jangwon Park\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\" Tokenization classes for KoBert model.\"\"\"\n","\n","\n","import logging\n","import os\n","import unicodedata\n","from shutil import copyfile\n","\n","from transformers import PreTrainedTokenizer\n","\n","\n","logger = logging.getLogger(__name__)\n","\n","VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n","                     \"vocab_txt\": \"vocab.txt\"}\n","\n","PRETRAINED_VOCAB_FILES_MAP = {\n","    \"vocab_file\": {\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n","    },\n","    \"vocab_txt\": {\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n","    }\n","}\n","\n","PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n","    \"monologg/kobert\": 512,\n","    \"monologg/kobert-lm\": 512,\n","    \"monologg/distilkobert\": 512\n","}\n","\n","PRETRAINED_INIT_CONFIGURATION = {\n","    \"monologg/kobert\": {\"do_lower_case\": False},\n","    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n","    \"monologg/distilkobert\": {\"do_lower_case\": False}\n","}\n","\n","SPIECE_UNDERLINE = u'▁'\n","\n","\n","class KoBertTokenizer(PreTrainedTokenizer):\n","    \"\"\"\n","        SentencePiece based tokenizer. Peculiarities:\n","            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n","    \"\"\"\n","    vocab_files_names = VOCAB_FILES_NAMES\n","    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n","    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n","    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n","\n","    def __init__(\n","            self,\n","            vocab_file,\n","            vocab_txt,\n","            do_lower_case=False,\n","            remove_space=True,\n","            keep_accents=False,\n","            unk_token=\"[UNK]\",\n","            sep_token=\"[SEP]\",\n","            pad_token=\"[PAD]\",\n","            cls_token=\"[CLS]\",\n","            mask_token=\"[MASK]\",\n","            **kwargs):\n","        super().__init__(\n","            unk_token=unk_token,\n","            sep_token=sep_token,\n","            pad_token=pad_token,\n","            cls_token=cls_token,\n","            mask_token=mask_token,\n","            **kwargs\n","        )\n","\n","        # Build vocab\n","        self.token2idx = dict()\n","        self.idx2token = []\n","        with open(vocab_txt, 'r', encoding='utf-8') as f:\n","            for idx, token in enumerate(f):\n","                token = token.strip()\n","                self.token2idx[token] = idx\n","                self.idx2token.append(token)\n","\n","        try:\n","            import sentencepiece as spm\n","        except ImportError:\n","            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n","                           \"pip install sentencepiece\")\n","\n","        self.do_lower_case = do_lower_case\n","        self.remove_space = remove_space\n","        self.keep_accents = keep_accents\n","        self.vocab_file = vocab_file\n","        self.vocab_txt = vocab_txt\n","\n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(vocab_file)\n","\n","    @property\n","    def vocab_size(self):\n","        return len(self.idx2token)\n","\n","    def get_vocab(self):\n","        return dict(self.token2idx, **self.added_tokens_encoder)\n","\n","    def __getstate__(self):\n","        state = self.__dict__.copy()\n","        state[\"sp_model\"] = None\n","        return state\n","\n","    def __setstate__(self, d):\n","        self.__dict__ = d\n","        try:\n","            import sentencepiece as spm\n","        except ImportError:\n","            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n","                           \"pip install sentencepiece\")\n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(self.vocab_file)\n","\n","    def preprocess_text(self, inputs):\n","        if self.remove_space:\n","            outputs = \" \".join(inputs.strip().split())\n","        else:\n","            outputs = inputs\n","        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n","\n","        if not self.keep_accents:\n","            outputs = unicodedata.normalize('NFKD', outputs)\n","            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n","        if self.do_lower_case:\n","            outputs = outputs.lower()\n","\n","        return outputs\n","\n","    def _tokenize(self, text, return_unicode=True, sample=False):\n","        \"\"\" Tokenize a string. \"\"\"\n","        text = self.preprocess_text(text)\n","\n","        if not sample:\n","            pieces = self.sp_model.EncodeAsPieces(text)\n","        else:\n","            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n","        new_pieces = []\n","        for piece in pieces:\n","            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n","                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n","                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n","                    if len(cur_pieces[0]) == 1:\n","                        cur_pieces = cur_pieces[1:]\n","                    else:\n","                        cur_pieces[0] = cur_pieces[0][1:]\n","                cur_pieces.append(piece[-1])\n","                new_pieces.extend(cur_pieces)\n","            else:\n","                new_pieces.append(piece)\n","\n","        return new_pieces\n","\n","    def _convert_token_to_id(self, token):\n","        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n","        return self.token2idx.get(token, self.token2idx[self.unk_token])\n","\n","    def _convert_id_to_token(self, index, return_unicode=True):\n","        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n","        return self.idx2token[index]\n","\n","    def convert_tokens_to_string(self, tokens):\n","        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n","        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n","        return out_string\n","\n","    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n","        \"\"\"\n","        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n","        by concatenating and adding special tokens.\n","        A KoBERT sequence has the following format:\n","            single sequence: [CLS] X [SEP]\n","            pair of sequences: [CLS] A [SEP] B [SEP]\n","        \"\"\"\n","        if token_ids_1 is None:\n","            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n","        cls = [self.cls_token_id]\n","        sep = [self.sep_token_id]\n","        return cls + token_ids_0 + sep + token_ids_1 + sep\n","\n","    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n","        \"\"\"\n","        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n","        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n","        Args:\n","            token_ids_0: list of ids (must not contain special tokens)\n","            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n","                for sequence pairs\n","            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n","                special tokens for the model\n","        Returns:\n","            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n","        \"\"\"\n","\n","        if already_has_special_tokens:\n","            if token_ids_1 is not None:\n","                raise ValueError(\n","                    \"You should not supply a second sequence if the provided sequence of \"\n","                    \"ids is already formated with special tokens for the model.\"\n","                )\n","            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n","\n","        if token_ids_1 is not None:\n","            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n","        return [1] + ([0] * len(token_ids_0)) + [1]\n","\n","    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n","        \"\"\"\n","        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n","        A KoBERT sequence pair mask has the following format:\n","        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n","        | first sequence    | second sequence\n","        if token_ids_1 is None, only returns the first portion of the mask (0's).\n","        \"\"\"\n","        sep = [self.sep_token_id]\n","        cls = [self.cls_token_id]\n","        if token_ids_1 is None:\n","            return len(cls + token_ids_0 + sep) * [0]\n","        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n","\n","    def save_vocabulary(self, save_directory):\n","        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n","            to a directory.\n","        \"\"\"\n","        if not os.path.isdir(save_directory):\n","            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n","            return\n","\n","        # 1. Save sentencepiece model\n","        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n","\n","        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n","            copyfile(self.vocab_file, out_vocab_model)\n","\n","        # 2. Save vocab.txt\n","        index = 0\n","        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n","        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n","            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n","                if index != token_index:\n","                    logger.warning(\n","                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n","                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n","                    )\n","                    index = token_index\n","                writer.write(token + \"\\n\")\n","                index += 1\n","\n","        return out_vocab_model, out_vocab_txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["30fbc7a93f554ba594e8d740635b9f39","228d9ee575c348aabc9753a37d69abe0","c90032a3d84145d5ad75d816ee1da433","25254b33b8e54615abe12625b3ca5db0","85bae951a61f4fc58ac3f1222614d75f","d9b83dda9f5f42c387d9156f0cb211be","390ec10f3ac54218b3324fdfb8c67811","8f294f85bf8d4a998cf2f79277459469","e52ffef0d2fa4db38214f148fabc45ca","371c1ba8620242b09165208968ebe6d8","291f623e7bde4e74a862a58b41ab2e3a","3eeec3ac381940cda584e578c3aa8053","3a4d2fcb89bd48b096545dd0bed177d0","7c619e1ed1b7498f8831d5fedb070f10","ccc5920652d24348958318becddc004a","0b42681294f5433f9af6d6e7201b39a1","56ddccd3e51f4b408edef6306840b050","5305c73bb46541b3a20cb97616679be7","239a7c59732e4092ba2a3c89cdbeeccc","ab86f374f9554244a6a1f8ae7fe89b1a","6383a885faac4052a82a5c4638217588","c725b4ceabef41008923d7210e718320","12f83dd5043e4fb088d92da4b97b444b","3059278d7fd446c3aa9ea4141046f523","fa3d861e6dbf4318bf4a63abbf4b590a","6b1376a9ffca406596ae9570fdbdb79d","eb1b620f9a2f4df09c650a1af4df32a0","00088c4c0ee347ba9e2b9f7997b01e56","4ff8ef43eb4f4cf8ad1e7a777084f79e","d66b9bec27f546ecbcae9b4d89a4cf2c","6455b78a8af34272a5702ed15ed81569","6033356b8e8d4f40bcfc8320a3ea589d","ba20d45f277a48a49e353c3f401f51a5","8e1b5c6c3deb44edbf4147c0e8c29894","68a61c77d03644db9faf5f86a1979851","c7346b8a061644c9a28912b6dae8fd99","39f876436ec04bda9d9dcd6e43726d72","1a553add063f45d6845e26fecf8dfc59","039df66e866a4c0daceae25169449e5a","07f2a8af595443828c3fa0a0ea1f33a2","b4dff72439014576a4e5077e05f028d6","ea3b02ba059a4b0ca897eb0242d09c0e","33c567e74f8e4559b185ca9e00c01a29","0dc71c95dc5f475780e8e692ab3e88b1","78f8a405b01f4212b6eb22054cfa1f51","c89f043a3b8f4e0898db7dd883dc345f","d1c06796bc8947279a7ff70b5c4d0dbf","022e6d92b11445719d08edfee49cb1a2","15ef21b1cb474c97be0d596776aa0875","748b420820f24ef58f19351cf191b0cf","2adb514e62974f9bbb77f20ba2dae2dc","80b1ed78d5404801b26e6417255b390b","db48d87d975d4e40a15c58d468db2ddc","9139268762be4e27bbd90889ecc7302c","b364367ba21743aa9cc8b053414c0d6d"],"output_embedded_package_id":"1kq_-lnSRkQHGsBGvCSgXdzVA9RRWMBd0"},"id":"J3O2Hzyd2TkN","outputId":"51dd1f2a-a3d3-40d3-d374-ef8ec8c526ce","executionInfo":{"status":"ok","timestamp":1640865676476,"user_tz":-540,"elapsed":6198939,"user":{"displayName":"Seongmin Mun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxXPWH0f2f0ThPPwM2evOCWKaCSlwmGiaeEFSK=s64","userId":"17295717412647902050"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["for currentTry in range(2,setTry):\n","  postpositions = [\"Eyse\",\"Ey\"] #\"Lo\"\n","  labelNumber = 0\n","  \n","  for postposition in postpositions:\n","\n","    import pandas as pd\n","\n","    fileDir = \"drive/My Drive/2022/AdverbialPostpositions/Data/test_\"+postposition+\".csv\"\n","    fr = open(fileDir, 'r')\n","    contents= fr.readlines()\n","    fr.close()\n","\n","    test = pd.DataFrame(columns=('index', 'Label', 'Sentence'))\n","    i = 0\n","    index = \"\"\n","    label = \"\"\n","    sentence = \"\"\n","    for content in contents:\n","        if i == 0:\n","            pass\n","        else:\n","            infos = content.split(\",\")\n","            index = infos[0]\n","            label = int(infos[1])\n","            sentence = infos[2].replace(\"\\n\",\"\")\n","            test.loc[i] = [index, label, sentence]\n","        i = i + 1\n","\n","    fileDir = \"drive/My Drive/2022/AdverbialPostpositions/Data/train_\"+postposition+\".csv\"\n","    fr = open(fileDir, 'r')\n","    contents= fr.readlines()\n","    fr.close()\n","\n","    train = pd.DataFrame(columns=('index', 'Label', 'Sentence'))\n","    i = 0\n","    index = \"\"\n","    label = \"\"\n","    sentence = \"\"\n","    for content in contents:\n","        if i == 0:\n","            pass\n","        else:\n","            infos = content.split(\",\")\n","            index = infos[0]\n","            label = int(infos[1])\n","            sentence = infos[2].replace(\"\\n\",\"\")\n","            train.loc[i] = [index, label, sentence]\n","        i = i + 1\n","\n","\n","    #정제하기\n","\n","    train['Sentence'] = train['Sentence'].str.replace(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》\\\\n\\t]+', \" \", regex=True)\n","    test['Sentence'] = test['Sentence'].str.replace(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', \" \", regex=True)\n","    train['Sentence'] = train['Sentence'].str.replace(r'\\t+', \" \", regex=True)\n","    test['Sentence'] = test['Sentence'].str.replace(r'\\t+', \" \", regex=True)\n","    train['Sentence'] = train['Sentence'].str.replace(r'[\\\\n]+',\" \", regex=True)\n","    train['Sentence'] = train['Sentence'].str.replace(r'[\\s]+', \" \", regex=True)\n","    train['Sentence'] = train['Sentence'].str.strip()\n","    test['Sentence'] = test['Sentence'].str.replace(r'[\\\\n]+',\" \", regex=True)\n","    test['Sentence'] = test['Sentence'].str.replace(r'[\\s]+', \" \", regex=True)\n","    test['Sentence'] = test['Sentence'].str.strip()\n","\n","    # train 문장 추출\n","    sentences = train['Sentence']\n","    # BERT의 입력 형식에 맞게 변환\n","    sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","\n","    # 라벨 추출\n","    labels = train['Label'].values\n","    labels_re = []\n","    for label in labels:\n","      labels_re.append(label)\n","    labels = labels_re\n","\n","    # BERT의 토크나이저로 문장을 토큰으로 분리\n","    tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","    # 입력 토큰의 최대 시퀀스 길이\n","    MAX_LEN = setMaxLength\n","\n","    # 토큰을 숫자 인덱스로 변환\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","\n","    # 어텐션 마스크 초기화\n","    attention_masks = []\n","\n","    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","\n","    # 훈련셋과 검증셋으로 분리\n","    train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n","                                                                                        labels, \n","                                                                                        random_state=2018, \n","                                                                                        test_size=0.1)\n","\n","    # 어텐션 마스크를 훈련셋과 검증셋으로 분리\n","    train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n","                                                          input_ids,\n","                                                          random_state=2018, \n","                                                          test_size=0.1)\n","\n","    # 데이터를 파이토치의 텐서로 변환\n","    train_inputs = torch.tensor(train_inputs)\n","    train_labels = torch.tensor(train_labels)\n","    train_masks = torch.tensor(train_masks)\n","    validation_inputs = torch.tensor(validation_inputs)\n","    validation_labels = torch.tensor(validation_labels)\n","    validation_masks = torch.tensor(validation_masks)\t\t\n","\n","    # 배치 사이즈\n","    batch_size = setBatch\n","\n","    # 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","    # 학습시 배치 사이즈 만큼 데이터를 가져옴\n","    train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","    train_sampler = RandomSampler(train_data)\n","    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","    validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","    validation_sampler = SequentialSampler(validation_data)\n","    validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","    # text 문장 추출\n","    sentences = test['Sentence']\n","\n","    # BERT의 입력 형식에 맞게 변환\n","    sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","\n","    # 라벨 추출\n","    labels = test['Label'].values\n","    labels_re = []\n","    for label in labels:\n","      labels_re.append(label)\n","    labels = labels_re\n","\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","    # 토큰을 숫자 인덱스로 변환\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","    # 어텐션 마스크 초기화\n","    attention_masks = []\n","\n","    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","\n","    # 데이터를 파이토치의 텐서로 변환\n","    test_inputs = torch.tensor(input_ids)\n","    test_labels = torch.tensor(labels)\n","    test_masks = torch.tensor(attention_masks)\n","\n","    # 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","    # 학습시 배치 사이즈 만큼 데이터를 가져옴\n","    test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","    test_sampler = RandomSampler(test_data)\n","    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n","    \n","\n","    # 입력 데이터 변환\n","    def convert_input_data(sentences):\n","\n","      # BERT의 토크나이저로 문장을 토큰으로 분리\n","      tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","      # 입력 토큰의 최대 시퀀스 길이\n","      MAX_LEN = setMaxLength\n","\n","      # 토큰을 숫자 인덱스로 변환\n","      input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","      \n","      # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","      input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","      # 어텐션 마스크 초기화\n","      attention_masks = []\n","\n","      # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","      # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","      for seq in input_ids:\n","          seq_mask = [float(i>0) for i in seq]\n","          attention_masks.append(seq_mask)\n","\n","      # 데이터를 파이토치의 텐서로 변환\n","      inputs = torch.tensor(input_ids)\n","      masks = torch.tensor(attention_masks)\n","\n","      return inputs, masks\n","\n","  \n","    if postposition == \"Lo\":#6\n","      labelNumber = 6\n","\n","      # 분류를 위한 BERT 모델 생성\n","      model = BertForSequenceClassification.from_pretrained(\"monologg/kobert\", num_labels=labelNumber)\n","      model.cuda()\n","\n","\n","      # 정확도 계산 함수\n","      def flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","          \n","      def FNS_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 0):\n","              match_num += 1\n","            if labels_flat[i] == 0:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      def INS_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 1):\n","              match_num += 1\n","            if labels_flat[i] == 1:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      def DIR_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 2):\n","              match_num += 1\n","            if labels_flat[i] == 2:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      def EFF_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 3):\n","              match_num += 1\n","            if labels_flat[i] == 3:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      def CRT_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 4):\n","              match_num += 1\n","            if labels_flat[i] == 4:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      def LOC_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 5):\n","              match_num += 1\n","            if labels_flat[i] == 5:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      # 시간 표시 함수\n","      def format_time(elapsed):\n","          # 반올림\n","          elapsed_rounded = int(round((elapsed)))\n","          \n","          # hh:mm:ss으로 형태 변경\n","          return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","      def outreault(guess):\n","        guess = int(guess)\n","        outFunction = \"\"\n","        if guess == 0:\n","          outFunction = \"FNS\"\n","        elif guess == 1:\n","          outFunction = \"INS\"\n","        elif guess == 2:\n","          outFunction = \"DIR\"\n","        elif guess == 3:\n","          outFunction = \"EFF\"\n","        elif guess == 4:\n","          outFunction = \"CRT\"\n","        elif guess == 5:\n","          outFunction = \"LOC\"\n","        return outFunction\n","\n","      # 옵티마이저 설정\n","      optimizer = AdamW(model.parameters(),\n","                        lr = setLearningRate, # 학습률\n","                        eps = setEpsilon # 0으로 나누는 것을 방지하기 위한 epsilon 값\n","                      )\n","\n","      # 에폭수\n","      epochs = setEpoch\n","\n","      # 총 훈련 스텝 : 배치반복 횟수 * 에폭\n","      total_steps = len(train_dataloader) * epochs\n","\n","      # 학습률을 조금씩 감소시키는 스케줄러 생성\n","      scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                  num_warmup_steps = 0,\n","                                                  num_training_steps = total_steps)\n","      \n","\n","      # 재현을 위해 랜덤시드 고정\n","      seed_val = setSeed\n","      random.seed(seed_val)\n","      np.random.seed(seed_val)\n","      torch.manual_seed(seed_val)\n","      torch.cuda.manual_seed_all(seed_val)\n","\n","      # 그래디언트 초기화\n","      model.zero_grad()\n","\n","      final_info = {}\n","\n","      f = open(\"drive/My Drive/2022/AdverbialPostpositions/Output/BERT/\"+postposition+\"/Outcomes/\"+postposition+\"_accuracy_trial_\"+str(currentTry)+\"_epoch_\"+str(epochs)+\".txt\", 'w')\n","      f.write(\"epoch,sentence,originalLabel,predictedLabel,predictedFunction,result\"+\"\\n\")\n","\n","      # 에폭만큼 반복\n","      for epoch_i in range(1, epochs):\n","          \n","          # ========================================\n","          #               Training\n","          # ========================================\n","          \n","          print(\"\")\n","          print('======== Epoch {:} / {:} ========'.format(epoch_i, epochs))\n","          print('Training...')\n","\n","          # 시작 시간 설정\n","          t0 = time.time()\n","\n","          # 로스 초기화\n","          total_loss = 0\n","\n","          # 훈련모드로 변경\n","          model.train()\n","              \n","          # 데이터로더에서 배치만큼 반복하여 가져옴\n","          for step, batch in enumerate(train_dataloader):\n","              # 경과 정보 표시\n","              if step % 500 == 0 and not step == 0:\n","                  elapsed = format_time(time.time() - t0)\n","                  print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","              # 배치를 GPU에 넣음\n","              batch = tuple(t.to(device) for t in batch)\n","              \n","              # 배치에서 데이터 추출\n","              b_input_ids, b_input_mask, b_labels = batch\n","\n","              # Forward 수행                \n","              outputs = model(b_input_ids, \n","                              token_type_ids=None, \n","                              attention_mask=b_input_mask, \n","                              labels=b_labels)\n","              \n","              # 로스 구함\n","              loss = outputs[0]\n","\n","              # 총 로스 계산\n","              total_loss += loss.item()\n","\n","              # Backward 수행으로 그래디언트 계산\n","              loss.backward()\n","\n","              # 그래디언트 클리핑\n","              torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","              # 그래디언트를 통해 가중치 파라미터 업데이트\n","              optimizer.step()\n","\n","              # 스케줄러로 학습률 감소\n","              scheduler.step()\n","\n","              # 그래디언트 초기화\n","              model.zero_grad()\n","\n","          # 평균 로스 계산\n","          avg_train_loss = total_loss / len(train_dataloader)            \n","\n","          print(\"\")\n","          print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","          print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","              \n","          # ========================================\n","          #               Validation\n","          # ========================================\n","\n","          print(\"\")\n","          print(\"Running Validation...\")\n","\n","          #시작 시간 설정\n","          t0 = time.time()\n","\n","          # 평가모드로 변경\n","          model.eval()\n","\n","          # 변수 초기화\n","          eval_loss, eval_accuracy = 0, 0\n","          nb_eval_steps, nb_eval_examples = 0, 0\n","          FNS_nb_eval_steps, FNS_eval_accuracy = 0, 0\n","          INS_nb_eval_steps, INS_eval_accuracy = 0, 0\n","          DIR_nb_eval_steps, DIR_eval_accuracy = 0, 0\n","          EFF_nb_eval_steps, EFF_eval_accuracy = 0, 0\n","          CRT_nb_eval_steps, CRT_eval_accuracy = 0, 0\n","          LOC_nb_eval_steps, LOC_eval_accuracy = 0, 0\n","\n","          epoch_info = {}\n","\n","          # 데이터로더에서 배치만큼 반복하여 가져옴\n","          for batch in test_dataloader:\n","              # 배치를 GPU에 넣음\n","              batch = tuple(t.to(device) for t in batch)\n","              \n","              # 배치에서 데이터 추출\n","              b_input_ids, b_input_mask, b_labels = batch\n","              \n","              # 그래디언트 계산 안함\n","              with torch.no_grad():     \n","                  # Forward 수행\n","                  outputs = model(b_input_ids, \n","                                  token_type_ids=None, \n","                                  attention_mask=b_input_mask)\n","              \n","              # 로스 구함\n","              logits = outputs[0]\n","\n","              # CPU로 데이터 이동\n","              logits = logits.detach().cpu().numpy()\n","              label_ids = b_labels.to('cpu').numpy()\n","              \n","              # 출력 로짓과 라벨을 비교하여 정확도 계산\n","              tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","              eval_accuracy += tmp_eval_accuracy\n","              nb_eval_steps += 1\n","\n","              FNS_tmp_eval_accuracy = FNS_flat_accuracy(logits, label_ids)\n","              FNS_eval_accuracy += FNS_tmp_eval_accuracy\n","              FNS_nb_eval_steps += 1\n","\n","              INS_tmp_eval_accuracy = INS_flat_accuracy(logits, label_ids)\n","              INS_eval_accuracy += INS_tmp_eval_accuracy\n","              INS_nb_eval_steps += 1\n","\n","              DIR_tmp_eval_accuracy = DIR_flat_accuracy(logits, label_ids)\n","              DIR_eval_accuracy += DIR_tmp_eval_accuracy\n","              DIR_nb_eval_steps += 1\n","\n","              EFF_tmp_eval_accuracy = EFF_flat_accuracy(logits, label_ids)\n","              EFF_eval_accuracy += EFF_tmp_eval_accuracy\n","              EFF_nb_eval_steps += 1\n","\n","              CRT_tmp_eval_accuracy = CRT_flat_accuracy(logits, label_ids)\n","              CRT_eval_accuracy += CRT_tmp_eval_accuracy\n","              CRT_nb_eval_steps += 1\n","\n","              LOC_tmp_eval_accuracy = LOC_flat_accuracy(logits, label_ids)\n","              LOC_eval_accuracy += LOC_tmp_eval_accuracy\n","              LOC_nb_eval_steps += 1\n","\n","          print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","          print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","          print(\"\")\n","          print(\"  Detail accuracy  \")\n","          print(\"  FNS_Accuracy: {0:.2f}\".format(FNS_eval_accuracy/FNS_nb_eval_steps))\n","          print(\"  INS_Accuracy: {0:.2f}\".format(INS_eval_accuracy/INS_nb_eval_steps))\n","          print(\"  DIR_Accuracy: {0:.2f}\".format(DIR_eval_accuracy/DIR_nb_eval_steps))\n","          print(\"  EFF_Accuracy: {0:.2f}\".format(EFF_eval_accuracy/EFF_nb_eval_steps))\n","          print(\"  CRT_Accuracy: {0:.2f}\".format(CRT_eval_accuracy/CRT_nb_eval_steps))\n","          print(\"  LOC_Accuracy: {0:.2f}\".format(LOC_eval_accuracy/LOC_nb_eval_steps))\n","\n","          epoch_info[\"Total\"] = round(eval_accuracy/nb_eval_steps,3)\n","          epoch_info[\"Loss\"] = round(avg_train_loss,3)\n","          epoch_info[\"FNS\"] = round(FNS_eval_accuracy/FNS_nb_eval_steps,3)\n","          epoch_info[\"INS\"] = round(INS_eval_accuracy/INS_nb_eval_steps,3)\n","          epoch_info[\"DIR\"] = round(DIR_eval_accuracy/DIR_nb_eval_steps,3)\n","          epoch_info[\"EFF\"] = round(EFF_eval_accuracy/EFF_nb_eval_steps,3)\n","          epoch_info[\"CRT\"] = round(CRT_eval_accuracy/CRT_nb_eval_steps,3)\n","          epoch_info[\"LOC\"] = round(LOC_eval_accuracy/LOC_nb_eval_steps,3)\n","\n","          final_info[\"epoch\"+str(epoch_i)] = epoch_info\n","\n","\n","          # 평가모드로 변경\n","          model.eval()\n","          test_input_ids = []\n","          test_input_mask = []\n","          test_labels = []\n","\n","          num = 0\n","          for step, batch in enumerate(test_data):   #467, 128\n","            # print(\"batch\",batch)\n","            # 배치를 GPU에 넣음\n","            batch = tuple(t.to(device) for t in batch)\n","            \n","            # 배치에서 데이터 추출\n","            b_input_ids, b_input_mask, b_labels = batch\n","            input_ids_arr = []\n","            input_mask_arr = []\n","\n","            \n","\n","            for i in range(0,len(b_input_ids)):\n","              input_ids_arr.append(int(b_input_ids[i]))\n","              input_mask_arr.append(int(b_input_mask[i]))\n","\n","            \n","            test_input_ids.append(input_ids_arr)\n","            test_input_mask.append(input_mask_arr)\n","            test_labels.append(int(b_labels))\n","\n","\n","          test_input_ids = torch.tensor(test_input_ids)\n","          test_input_mask = torch.tensor(test_input_mask)\n","          test_labels = test_labels\n","\n","          test_input_ids = test_input_ids.to(device)\n","          test_input_mask = test_input_mask.to(device)\n","\n","\n","          # 그래디언트 계산 안함\n","          with torch.no_grad():     \n","              # Forward 수행\n","              outputs = model(test_input_ids, \n","                              token_type_ids=None, \n","                              attention_mask=test_input_mask)\n","              \n","\n","          sentence_vecs_sum = outputs[0]\n","\n","          sentence_array = []\n","          for i in range(0,len(sentence_vecs_sum)):\n","            each_array = []\n","            for j in range(0,len(sentence_vecs_sum[i])):\n","              each_array.append(float(sentence_vecs_sum[i][j]))\n","            sentence_array.append(each_array)\n","\n","          initial_df = pd.DataFrame(sentence_array)\n","\n","          from sklearn.manifold import TSNE\n","          tsne = TSNE(n_components=2, random_state=0)\n","          tsne_obj= tsne.fit_transform(initial_df)\n","\n","          tsne_df = pd.DataFrame({'X':tsne_obj[:,0],'Y':tsne_obj[:,1],'Label':test_labels})\n","\n","          tsne_df.to_csv(\"drive/My Drive/2022/AdverbialPostpositions/Output/BERT/\"+postposition+\"/t-SNE/\"+postposition+\"_tSNE_trial_\"+str(currentTry)+\"_epoch_\"+str(epoch_i)+\".csv\")\n","\n","          import numpy as np   \n","          import pandas as pd \n","          from plotnine import *\n","\n","          print(\"\")\n","          print(\"  Network visualization  \")\n","          print(ggplot(tsne_df, aes(x='X', y='Y')) + geom_point(aes(colour = 'Label')))\n","\n","          # 문장 테스트\n","          def test_sentences(sentences):\n","\n","              # 평가모드로 변경\n","              model.eval()\n","\n","              # 문장을 입력 데이터로 변환\n","              inputs, masks = convert_input_data(sentences)\n","\n","              # 데이터를 GPU에 넣음\n","              b_input_ids = inputs.to(device)\n","              b_input_mask = masks.to(device)\n","                      \n","              # 그래디언트 계산 안함\n","              with torch.no_grad():     \n","                  # Forward 수행\n","                  outputs = model(b_input_ids, \n","                                  token_type_ids=None, \n","                                  attention_mask=b_input_mask)\n","\n","              # 로스 구함\n","              logits = outputs[0]\n","\n","              # CPU로 데이터 이동\n","              logits = logits.detach().cpu().numpy()\n","\n","              return logits\n","\n","\n","          testSentences = test['Sentence']\n","\n","          totalNum = 0\n","          correctNum = 0\n","          for each in range(0, len(testSentences)):\n","              # print(test['Label'][each + 1], test['Sentence'][each + 1])\n","              logits = test_sentences([test['Sentence'][each + 1]])\n","              guess = str(np.argmax(logits))\n","              if guess == str(test['Label'][each + 1]) :\n","                  # print(\"input: \", test['Sentence'][each + 1], \", predict: \", guess, \"(O)\")\n","                  f.write(str(epoch_i) + \",\" + test['Sentence'][each + 1] + \",\" + str(test['Label'][each + 1]) + \",\" + guess + \",\" + outreault(guess)+ \",1\" + \"\\n\")\n","                  correctNum = correctNum + 1\n","              else:\n","                  f.write(str(epoch_i) + \",\" + test['Sentence'][each + 1] + \",\" + str(test['Label'][each + 1]) + \",\" + guess + \",\" + outreault(guess) + \",0\" + \"\\n\")       \n","                  # print(\"input: \", test['Sentence'][each + 1], \", predict: \", guess, \"(X)\")\n","              totalNum = totalNum + 1\n","\n","          print(\"totalNum: \", totalNum, \" correctNum: \", correctNum, \" accuracy: \", (correctNum/totalNum))\n","\n","      print(\"\")\n","      print(\"Training complete!\")\n","      print(\"\")\n","      print(\"Final result is below!\")\n","      print(final_info)\n","\n","      f.close()\n","\n","\n","\n","    elif postposition == \"Eyse\":#2\n","      labelNumber = 2\n","\n","      # 분류를 위한 BERT 모델 생성\n","      model = BertForSequenceClassification.from_pretrained(\"monologg/kobert\", num_labels=labelNumber)\n","      model.cuda()\n","\n","\n","      # 정확도 계산 함수\n","      def flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","          \n","      def SRC_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 0):\n","              match_num += 1\n","            if labels_flat[i] == 0:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      def LOC_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 1):\n","              match_num += 1\n","            if labels_flat[i] == 1:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      # 시간 표시 함수\n","      def format_time(elapsed):\n","          # 반올림\n","          elapsed_rounded = int(round((elapsed)))\n","          \n","          # hh:mm:ss으로 형태 변경\n","          return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","      def outreault(guess):\n","        guess = int(guess)\n","        outFunction = \"\"\n","        if guess == 0:\n","          outFunction = \"SRC\"\n","        elif guess == 1:\n","          outFunction = \"LOC\"\n","        return outFunction\n","\n","      # 옵티마이저 설정\n","      optimizer = AdamW(model.parameters(),\n","                        lr = setLearningRate, # 학습률\n","                        eps = setEpsilon # 0으로 나누는 것을 방지하기 위한 epsilon 값\n","                      )\n","\n","      # 에폭수\n","      epochs = setEpoch\n","\n","      # 총 훈련 스텝 : 배치반복 횟수 * 에폭\n","      total_steps = len(train_dataloader) * epochs\n","\n","      # 학습률을 조금씩 감소시키는 스케줄러 생성\n","      scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                  num_warmup_steps = 0,\n","                                                  num_training_steps = total_steps)\n","      \n","\n","      # 재현을 위해 랜덤시드 고정\n","      seed_val = setSeed\n","      random.seed(seed_val)\n","      np.random.seed(seed_val)\n","      torch.manual_seed(seed_val)\n","      torch.cuda.manual_seed_all(seed_val)\n","\n","      # 그래디언트 초기화\n","      model.zero_grad()\n","\n","      final_info = {}\n","\n","      f = open(\"drive/My Drive/2022/AdverbialPostpositions/Output/BERT/\"+postposition+\"/Outcomes/\"+postposition+\"_accuracy_trial_\"+str(currentTry)+\"_epoch_\"+str(epochs)+\".txt\", 'w')\n","      f.write(\"epoch,sentence,originalLabel,predictedLabel,predictedFunction,result\"+\"\\n\")\n","\n","      # 에폭만큼 반복\n","      for epoch_i in range(1, epochs):\n","          \n","          # ========================================\n","          #               Training\n","          # ========================================\n","          \n","          print(\"\")\n","          print('======== Epoch {:} / {:} ========'.format(epoch_i, epochs))\n","          print('Training...')\n","\n","          # 시작 시간 설정\n","          t0 = time.time()\n","\n","          # 로스 초기화\n","          total_loss = 0\n","\n","          # 훈련모드로 변경\n","          model.train()\n","              \n","          # 데이터로더에서 배치만큼 반복하여 가져옴\n","          for step, batch in enumerate(train_dataloader):\n","              # 경과 정보 표시\n","              if step % 500 == 0 and not step == 0:\n","                  elapsed = format_time(time.time() - t0)\n","                  print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","              # 배치를 GPU에 넣음\n","              batch = tuple(t.to(device) for t in batch)\n","              \n","              # 배치에서 데이터 추출\n","              b_input_ids, b_input_mask, b_labels = batch\n","\n","              # Forward 수행                \n","              outputs = model(b_input_ids, \n","                              token_type_ids=None, \n","                              attention_mask=b_input_mask, \n","                              labels=b_labels)\n","              \n","              # 로스 구함\n","              loss = outputs[0]\n","\n","              # 총 로스 계산\n","              total_loss += loss.item()\n","\n","              # Backward 수행으로 그래디언트 계산\n","              loss.backward()\n","\n","              # 그래디언트 클리핑\n","              torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","              # 그래디언트를 통해 가중치 파라미터 업데이트\n","              optimizer.step()\n","\n","              # 스케줄러로 학습률 감소\n","              scheduler.step()\n","\n","              # 그래디언트 초기화\n","              model.zero_grad()\n","\n","          # 평균 로스 계산\n","          avg_train_loss = total_loss / len(train_dataloader)            \n","\n","          print(\"\")\n","          print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","          print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","              \n","          # ========================================\n","          #               Validation\n","          # ========================================\n","\n","          print(\"\")\n","          print(\"Running Validation...\")\n","\n","          #시작 시간 설정\n","          t0 = time.time()\n","\n","          # 평가모드로 변경\n","          model.eval()\n","\n","          # 변수 초기화\n","          eval_loss, eval_accuracy = 0, 0\n","          nb_eval_steps, nb_eval_examples = 0, 0\n","          SRC_nb_eval_steps, SRC_eval_accuracy = 0, 0\n","          LOC_nb_eval_steps, LOC_eval_accuracy = 0, 0\n","\n","          epoch_info = {}\n","\n","          # 데이터로더에서 배치만큼 반복하여 가져옴\n","          for batch in test_dataloader:\n","              # 배치를 GPU에 넣음\n","              batch = tuple(t.to(device) for t in batch)\n","              \n","              # 배치에서 데이터 추출\n","              b_input_ids, b_input_mask, b_labels = batch\n","              \n","              # 그래디언트 계산 안함\n","              with torch.no_grad():     \n","                  # Forward 수행\n","                  outputs = model(b_input_ids, \n","                                  token_type_ids=None, \n","                                  attention_mask=b_input_mask)\n","              \n","              # 로스 구함\n","              logits = outputs[0]\n","\n","              # CPU로 데이터 이동\n","              logits = logits.detach().cpu().numpy()\n","              label_ids = b_labels.to('cpu').numpy()\n","              \n","              # 출력 로짓과 라벨을 비교하여 정확도 계산\n","              tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","              eval_accuracy += tmp_eval_accuracy\n","              nb_eval_steps += 1\n","\n","              SRC_tmp_eval_accuracy = SRC_flat_accuracy(logits, label_ids)\n","              SRC_eval_accuracy += SRC_tmp_eval_accuracy\n","              SRC_nb_eval_steps += 1\n","\n","              LOC_tmp_eval_accuracy = LOC_flat_accuracy(logits, label_ids)\n","              LOC_eval_accuracy += LOC_tmp_eval_accuracy\n","              LOC_nb_eval_steps += 1\n","\n","          print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","          print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","          print(\"\")\n","          print(\"  Detail accuracy  \")\n","          print(\"  SRC_Accuracy: {0:.2f}\".format(SRC_eval_accuracy/SRC_nb_eval_steps))\n","          print(\"  LOC_Accuracy: {0:.2f}\".format(LOC_eval_accuracy/LOC_nb_eval_steps))\n","\n","          epoch_info[\"Total\"] = round(eval_accuracy/nb_eval_steps,3)\n","          epoch_info[\"Loss\"] = round(avg_train_loss,3)\n","          epoch_info[\"SRC\"] = round(SRC_eval_accuracy/SRC_nb_eval_steps,3)\n","          epoch_info[\"LOC\"] = round(LOC_eval_accuracy/LOC_nb_eval_steps,3)\n","\n","          final_info[\"epoch\"+str(epoch_i)] = epoch_info\n","\n","\n","          # 평가모드로 변경\n","          model.eval()\n","          test_input_ids = []\n","          test_input_mask = []\n","          test_labels = []\n","\n","          num = 0\n","          for step, batch in enumerate(test_data):   #467, 128\n","            # print(\"batch\",batch)\n","            # 배치를 GPU에 넣음\n","            batch = tuple(t.to(device) for t in batch)\n","            \n","            # 배치에서 데이터 추출\n","            b_input_ids, b_input_mask, b_labels = batch\n","            input_ids_arr = []\n","            input_mask_arr = []\n","\n","            \n","\n","            for i in range(0,len(b_input_ids)):\n","              input_ids_arr.append(int(b_input_ids[i]))\n","              input_mask_arr.append(int(b_input_mask[i]))\n","\n","            \n","            test_input_ids.append(input_ids_arr)\n","            test_input_mask.append(input_mask_arr)\n","            test_labels.append(int(b_labels))\n","\n","\n","          test_input_ids = torch.tensor(test_input_ids)\n","          test_input_mask = torch.tensor(test_input_mask)\n","          test_labels = test_labels\n","\n","          test_input_ids = test_input_ids.to(device)\n","          test_input_mask = test_input_mask.to(device)\n","\n","\n","          # 그래디언트 계산 안함\n","          with torch.no_grad():     \n","              # Forward 수행\n","              outputs = model(test_input_ids, \n","                              token_type_ids=None, \n","                              attention_mask=test_input_mask)\n","              \n","\n","          sentence_vecs_sum = outputs[0]\n","\n","          sentence_array = []\n","          for i in range(0,len(sentence_vecs_sum)):\n","            each_array = []\n","            for j in range(0,len(sentence_vecs_sum[i])):\n","              each_array.append(float(sentence_vecs_sum[i][j]))\n","            sentence_array.append(each_array)\n","\n","          initial_df = pd.DataFrame(sentence_array)\n","\n","          from sklearn.manifold import TSNE\n","          tsne = TSNE(n_components=2, random_state=0)\n","          tsne_obj= tsne.fit_transform(initial_df)\n","\n","          tsne_df = pd.DataFrame({'X':tsne_obj[:,0],'Y':tsne_obj[:,1],'Label':test_labels})\n","\n","          tsne_df.to_csv(\"drive/My Drive/2022/AdverbialPostpositions/Output/BERT/\"+postposition+\"/t-SNE/\"+postposition+\"_tSNE_trial_\"+str(currentTry)+\"_epoch_\"+str(epoch_i)+\".csv\")\n","\n","          import numpy as np   \n","          import pandas as pd \n","          from plotnine import *\n","\n","          print(\"\")\n","          print(\"  Network visualization  \")\n","          print(ggplot(tsne_df, aes(x='X', y='Y')) + geom_point(aes(colour = 'Label')))\n","\n","          # 문장 테스트\n","          def test_sentences(sentences):\n","\n","              # 평가모드로 변경\n","              model.eval()\n","\n","              # 문장을 입력 데이터로 변환\n","              inputs, masks = convert_input_data(sentences)\n","\n","              # 데이터를 GPU에 넣음\n","              b_input_ids = inputs.to(device)\n","              b_input_mask = masks.to(device)\n","                      \n","              # 그래디언트 계산 안함\n","              with torch.no_grad():     \n","                  # Forward 수행\n","                  outputs = model(b_input_ids, \n","                                  token_type_ids=None, \n","                                  attention_mask=b_input_mask)\n","\n","              # 로스 구함\n","              logits = outputs[0]\n","\n","              # CPU로 데이터 이동\n","              logits = logits.detach().cpu().numpy()\n","\n","              return logits\n","\n","\n","          testSentences = test['Sentence']\n","\n","          totalNum = 0\n","          correctNum = 0\n","          for each in range(0, len(testSentences)):\n","              # print(test['Label'][each + 1], test['Sentence'][each + 1])\n","              logits = test_sentences([test['Sentence'][each + 1]])\n","              guess = str(np.argmax(logits))\n","              if guess == str(test['Label'][each + 1]) :\n","                  # print(\"input: \", test['Sentence'][each + 1], \", predict: \", guess, \"(O)\")\n","                  f.write(str(epoch_i) + \",\" + test['Sentence'][each + 1] + \",\" + str(test['Label'][each + 1]) + \",\" + guess + \",\" + outreault(guess)+ \",1\" + \"\\n\")\n","                  correctNum = correctNum + 1\n","              else:\n","                  f.write(str(epoch_i) + \",\" + test['Sentence'][each + 1] + \",\" + str(test['Label'][each + 1]) + \",\" + guess + \",\" + outreault(guess) + \",0\" + \"\\n\")       \n","                  # print(\"input: \", test['Sentence'][each + 1], \", predict: \", guess, \"(X)\")\n","              totalNum = totalNum + 1\n","\n","          print(\"totalNum: \", totalNum, \" correctNum: \", correctNum, \" accuracy: \", (correctNum/totalNum))\n","\n","      print(\"\")\n","      print(\"Training complete!\")\n","      print(\"\")\n","      print(\"Final result is below!\")\n","      print(final_info)\n","\n","      f.close()\n","\n","        \n","    elif postposition == \"Ey\":#8\n","      labelNumber = 8\n","\n","      # 분류를 위한 BERT 모델 생성\n","      model = BertForSequenceClassification.from_pretrained(\"monologg/kobert\", num_labels=labelNumber)\n","      model.cuda()\n","\n","\n","      # 정확도 계산 함수\n","      def flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","          \n","      def FNS_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 0):\n","              match_num += 1\n","            if labels_flat[i] == 0:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      def INS_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 1):\n","              match_num += 1\n","            if labels_flat[i] == 1:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      def GOL_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 2):\n","              match_num += 1\n","            if labels_flat[i] == 2:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      def EFF_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 3):\n","              match_num += 1\n","            if labels_flat[i] == 3:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      def CRT_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 4):\n","              match_num += 1\n","            if labels_flat[i] == 4:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      def LOC_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 5):\n","              match_num += 1\n","            if labels_flat[i] == 5:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      def AGT_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 6):\n","              match_num += 1\n","            if labels_flat[i] == 6:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      def THM_flat_accuracy(preds, labels):\n","          \n","          pred_flat = np.argmax(preds, axis=1).flatten()\n","          labels_flat = labels.flatten()\n","\n","          match_num = 0\n","          func_num = 0\n","          for i in range(0,len(pred_flat)):\n","            #print(pred_flat[i],\" / \",labels_flat[i])\n","            if (pred_flat[i] == labels_flat[i]) and (labels_flat[i] == 7):\n","              match_num += 1\n","            if labels_flat[i] == 7:\n","              func_num += 1\n","\n","          if match_num == 0 or func_num == 0:\n","            return 0\n","          else:\n","            return match_num / func_num\n","\n","      # 시간 표시 함수\n","      def format_time(elapsed):\n","          # 반올림\n","          elapsed_rounded = int(round((elapsed)))\n","          \n","          # hh:mm:ss으로 형태 변경\n","          return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","      def outreault(guess):\n","        guess = int(guess)\n","        outFunction = \"\"\n","        if guess == 0:\n","          outFunction = \"FNS\"\n","        elif guess == 1:\n","          outFunction = \"INS\"\n","        elif guess == 2:\n","          outFunction = \"GOL\"\n","        elif guess == 3:\n","          outFunction = \"EFF\"\n","        elif guess == 4:\n","          outFunction = \"CRT\"\n","        elif guess == 5:\n","          outFunction = \"LOC\"\n","        elif guess == 6:\n","          outFunction = \"AGT\"\n","        elif guess == 7:\n","          outFunction = \"THM\"\n","        return outFunction\n","\n","      # 옵티마이저 설정\n","      optimizer = AdamW(model.parameters(),\n","                        lr = setLearningRate, # 학습률\n","                        eps = setEpsilon # 0으로 나누는 것을 방지하기 위한 epsilon 값\n","                      )\n","\n","      # 에폭수\n","      epochs = setEpoch\n","\n","      # 총 훈련 스텝 : 배치반복 횟수 * 에폭\n","      total_steps = len(train_dataloader) * epochs\n","\n","      # 학습률을 조금씩 감소시키는 스케줄러 생성\n","      scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                  num_warmup_steps = 0,\n","                                                  num_training_steps = total_steps)\n","      \n","\n","      # 재현을 위해 랜덤시드 고정\n","      seed_val = setSeed\n","      random.seed(seed_val)\n","      np.random.seed(seed_val)\n","      torch.manual_seed(seed_val)\n","      torch.cuda.manual_seed_all(seed_val)\n","\n","      # 그래디언트 초기화\n","      model.zero_grad()\n","\n","      final_info = {}\n","\n","      f = open(\"drive/My Drive/2022/AdverbialPostpositions/Output/BERT/\"+postposition+\"/Outcomes/\"+postposition+\"_accuracy_trial_\"+str(currentTry)+\"_epoch_\"+str(epochs)+\".txt\", 'w')\n","      f.write(\"epoch,sentence,originalLabel,predictedLabel,predictedFunction,result\"+\"\\n\")\n","\n","      # 에폭만큼 반복\n","      for epoch_i in range(1, epochs):\n","          \n","          # ========================================\n","          #               Training\n","          # ========================================\n","          \n","          print(\"\")\n","          print('======== Epoch {:} / {:} ========'.format(epoch_i, epochs))\n","          print('Training...')\n","\n","          # 시작 시간 설정\n","          t0 = time.time()\n","\n","          # 로스 초기화\n","          total_loss = 0\n","\n","          # 훈련모드로 변경\n","          model.train()\n","              \n","          # 데이터로더에서 배치만큼 반복하여 가져옴\n","          for step, batch in enumerate(train_dataloader):\n","              # 경과 정보 표시\n","              if step % 500 == 0 and not step == 0:\n","                  elapsed = format_time(time.time() - t0)\n","                  print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","              # 배치를 GPU에 넣음\n","              batch = tuple(t.to(device) for t in batch)\n","              \n","              # 배치에서 데이터 추출\n","              b_input_ids, b_input_mask, b_labels = batch\n","\n","              # Forward 수행                \n","              outputs = model(b_input_ids, \n","                              token_type_ids=None, \n","                              attention_mask=b_input_mask, \n","                              labels=b_labels)\n","              \n","              # 로스 구함\n","              loss = outputs[0]\n","\n","              # 총 로스 계산\n","              total_loss += loss.item()\n","\n","              # Backward 수행으로 그래디언트 계산\n","              loss.backward()\n","\n","              # 그래디언트 클리핑\n","              torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","              # 그래디언트를 통해 가중치 파라미터 업데이트\n","              optimizer.step()\n","\n","              # 스케줄러로 학습률 감소\n","              scheduler.step()\n","\n","              # 그래디언트 초기화\n","              model.zero_grad()\n","\n","          # 평균 로스 계산\n","          avg_train_loss = total_loss / len(train_dataloader)            \n","\n","          print(\"\")\n","          print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","          print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","              \n","          # ========================================\n","          #               Validation\n","          # ========================================\n","\n","          print(\"\")\n","          print(\"Running Validation...\")\n","\n","          #시작 시간 설정\n","          t0 = time.time()\n","\n","          # 평가모드로 변경\n","          model.eval()\n","\n","          # 변수 초기화\n","          eval_loss, eval_accuracy = 0, 0\n","          nb_eval_steps, nb_eval_examples = 0, 0\n","          FNS_nb_eval_steps, FNS_eval_accuracy = 0, 0\n","          INS_nb_eval_steps, INS_eval_accuracy = 0, 0\n","          GOL_nb_eval_steps, GOL_eval_accuracy = 0, 0\n","          EFF_nb_eval_steps, EFF_eval_accuracy = 0, 0\n","          CRT_nb_eval_steps, CRT_eval_accuracy = 0, 0\n","          LOC_nb_eval_steps, LOC_eval_accuracy = 0, 0\n","          AGT_nb_eval_steps, AGT_eval_accuracy = 0, 0\n","          THM_nb_eval_steps, THM_eval_accuracy = 0, 0\n","\n","          epoch_info = {}\n","\n","          # 데이터로더에서 배치만큼 반복하여 가져옴\n","          for batch in test_dataloader:\n","              # 배치를 GPU에 넣음\n","              batch = tuple(t.to(device) for t in batch)\n","              \n","              # 배치에서 데이터 추출\n","              b_input_ids, b_input_mask, b_labels = batch\n","              \n","              # 그래디언트 계산 안함\n","              with torch.no_grad():     \n","                  # Forward 수행\n","                  outputs = model(b_input_ids, \n","                                  token_type_ids=None, \n","                                  attention_mask=b_input_mask)\n","              \n","              # 로스 구함\n","              logits = outputs[0]\n","\n","              # CPU로 데이터 이동\n","              logits = logits.detach().cpu().numpy()\n","              label_ids = b_labels.to('cpu').numpy()\n","              \n","              # 출력 로짓과 라벨을 비교하여 정확도 계산\n","              tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","              eval_accuracy += tmp_eval_accuracy\n","              nb_eval_steps += 1\n","\n","              FNS_tmp_eval_accuracy = FNS_flat_accuracy(logits, label_ids)\n","              FNS_eval_accuracy += FNS_tmp_eval_accuracy\n","              FNS_nb_eval_steps += 1\n","\n","              INS_tmp_eval_accuracy = INS_flat_accuracy(logits, label_ids)\n","              INS_eval_accuracy += INS_tmp_eval_accuracy\n","              INS_nb_eval_steps += 1\n","\n","              GOL_tmp_eval_accuracy = GOL_flat_accuracy(logits, label_ids)\n","              GOL_eval_accuracy += GOL_tmp_eval_accuracy\n","              GOL_nb_eval_steps += 1\n","\n","              EFF_tmp_eval_accuracy = EFF_flat_accuracy(logits, label_ids)\n","              EFF_eval_accuracy += EFF_tmp_eval_accuracy\n","              EFF_nb_eval_steps += 1\n","\n","              CRT_tmp_eval_accuracy = CRT_flat_accuracy(logits, label_ids)\n","              CRT_eval_accuracy += CRT_tmp_eval_accuracy\n","              CRT_nb_eval_steps += 1\n","\n","              LOC_tmp_eval_accuracy = LOC_flat_accuracy(logits, label_ids)\n","              LOC_eval_accuracy += LOC_tmp_eval_accuracy\n","              LOC_nb_eval_steps += 1\n","\n","              AGT_tmp_eval_accuracy = AGT_flat_accuracy(logits, label_ids)\n","              AGT_eval_accuracy += AGT_tmp_eval_accuracy\n","              AGT_nb_eval_steps += 1\n","\n","              THM_tmp_eval_accuracy = THM_flat_accuracy(logits, label_ids)\n","              THM_eval_accuracy += THM_tmp_eval_accuracy\n","              THM_nb_eval_steps += 1\n","\n","          print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","          print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","          print(\"\")\n","          print(\"  Detail accuracy  \")\n","          print(\"  FNS_Accuracy: {0:.2f}\".format(FNS_eval_accuracy/FNS_nb_eval_steps))\n","          print(\"  INS_Accuracy: {0:.2f}\".format(INS_eval_accuracy/INS_nb_eval_steps))\n","          print(\"  GOL_Accuracy: {0:.2f}\".format(GOL_eval_accuracy/GOL_nb_eval_steps))\n","          print(\"  EFF_Accuracy: {0:.2f}\".format(EFF_eval_accuracy/EFF_nb_eval_steps))\n","          print(\"  CRT_Accuracy: {0:.2f}\".format(CRT_eval_accuracy/CRT_nb_eval_steps))\n","          print(\"  LOC_Accuracy: {0:.2f}\".format(LOC_eval_accuracy/LOC_nb_eval_steps))\n","          print(\"  AGT_Accuracy: {0:.2f}\".format(AGT_eval_accuracy/AGT_nb_eval_steps))\n","          print(\"  THM_Accuracy: {0:.2f}\".format(THM_eval_accuracy/THM_nb_eval_steps))\n","\n","          epoch_info[\"Total\"] = round(eval_accuracy/nb_eval_steps,3)\n","          epoch_info[\"Loss\"] = round(avg_train_loss,3)\n","          epoch_info[\"FNS\"] = round(FNS_eval_accuracy/FNS_nb_eval_steps,3)\n","          epoch_info[\"INS\"] = round(INS_eval_accuracy/INS_nb_eval_steps,3)\n","          epoch_info[\"GOL\"] = round(GOL_eval_accuracy/GOL_nb_eval_steps,3)\n","          epoch_info[\"EFF\"] = round(EFF_eval_accuracy/EFF_nb_eval_steps,3)\n","          epoch_info[\"CRT\"] = round(CRT_eval_accuracy/CRT_nb_eval_steps,3)\n","          epoch_info[\"LOC\"] = round(LOC_eval_accuracy/LOC_nb_eval_steps,3)\n","          epoch_info[\"AGT\"] = round(AGT_eval_accuracy/AGT_nb_eval_steps,3)\n","          epoch_info[\"THM\"] = round(THM_eval_accuracy/THM_nb_eval_steps,3)\n","\n","          final_info[\"epoch\"+str(epoch_i)] = epoch_info\n","\n","\n","          # 평가모드로 변경\n","          model.eval()\n","          test_input_ids = []\n","          test_input_mask = []\n","          test_labels = []\n","\n","          num = 0\n","          for step, batch in enumerate(test_data):   #467, 128\n","            # print(\"batch\",batch)\n","            # 배치를 GPU에 넣음\n","            batch = tuple(t.to(device) for t in batch)\n","            \n","            # 배치에서 데이터 추출\n","            b_input_ids, b_input_mask, b_labels = batch\n","            input_ids_arr = []\n","            input_mask_arr = []\n","\n","            \n","\n","            for i in range(0,len(b_input_ids)):\n","              input_ids_arr.append(int(b_input_ids[i]))\n","              input_mask_arr.append(int(b_input_mask[i]))\n","\n","            \n","            test_input_ids.append(input_ids_arr)\n","            test_input_mask.append(input_mask_arr)\n","            test_labels.append(int(b_labels))\n","\n","\n","          test_input_ids = torch.tensor(test_input_ids)\n","          test_input_mask = torch.tensor(test_input_mask)\n","          test_labels = test_labels\n","\n","          test_input_ids = test_input_ids.to(device)\n","          test_input_mask = test_input_mask.to(device)\n","\n","\n","          # 그래디언트 계산 안함\n","          with torch.no_grad():     \n","              # Forward 수행\n","              outputs = model(test_input_ids, \n","                              token_type_ids=None, \n","                              attention_mask=test_input_mask)\n","              \n","\n","          sentence_vecs_sum = outputs[0]\n","\n","          sentence_array = []\n","          for i in range(0,len(sentence_vecs_sum)):\n","            each_array = []\n","            for j in range(0,len(sentence_vecs_sum[i])):\n","              each_array.append(float(sentence_vecs_sum[i][j]))\n","            sentence_array.append(each_array)\n","\n","          initial_df = pd.DataFrame(sentence_array)\n","\n","          from sklearn.manifold import TSNE\n","          tsne = TSNE(n_components=2, random_state=0)\n","          tsne_obj= tsne.fit_transform(initial_df)\n","\n","          tsne_df = pd.DataFrame({'X':tsne_obj[:,0],'Y':tsne_obj[:,1],'Label':test_labels})\n","\n","          tsne_df.to_csv(\"drive/My Drive/2022/AdverbialPostpositions/Output/BERT/\"+postposition+\"/t-SNE/\"+postposition+\"_tSNE_trial_\"+str(currentTry)+\"_epoch_\"+str(epoch_i)+\".csv\")\n","\n","          import numpy as np   \n","          import pandas as pd \n","          from plotnine import *\n","\n","          print(\"\")\n","          print(\"  Network visualization  \")\n","          print(ggplot(tsne_df, aes(x='X', y='Y')) + geom_point(aes(colour = 'Label')))\n","\n","          # 문장 테스트\n","          def test_sentences(sentences):\n","\n","              # 평가모드로 변경\n","              model.eval()\n","\n","              # 문장을 입력 데이터로 변환\n","              inputs, masks = convert_input_data(sentences)\n","\n","              # 데이터를 GPU에 넣음\n","              b_input_ids = inputs.to(device)\n","              b_input_mask = masks.to(device)\n","                      \n","              # 그래디언트 계산 안함\n","              with torch.no_grad():     \n","                  # Forward 수행\n","                  outputs = model(b_input_ids, \n","                                  token_type_ids=None, \n","                                  attention_mask=b_input_mask)\n","\n","              # 로스 구함\n","              logits = outputs[0]\n","\n","              # CPU로 데이터 이동\n","              logits = logits.detach().cpu().numpy()\n","\n","              return logits\n","\n","\n","          testSentences = test['Sentence']\n","\n","          totalNum = 0\n","          correctNum = 0\n","          for each in range(0, len(testSentences)):\n","              # print(test['Label'][each + 1], test['Sentence'][each + 1])\n","              logits = test_sentences([test['Sentence'][each + 1]])\n","              guess = str(np.argmax(logits))\n","              if guess == str(test['Label'][each + 1]) :\n","                  # print(\"input: \", test['Sentence'][each + 1], \", predict: \", guess, \"(O)\")\n","                  f.write(str(epoch_i) + \",\" + test['Sentence'][each + 1] + \",\" + str(test['Label'][each + 1]) + \",\" + guess + \",\" + outreault(guess)+ \",1\" + \"\\n\")\n","                  correctNum = correctNum + 1\n","              else:\n","                  f.write(str(epoch_i) + \",\" + test['Sentence'][each + 1] + \",\" + str(test['Label'][each + 1]) + \",\" + guess + \",\" + outreault(guess) + \",0\" + \"\\n\")       \n","                  # print(\"input: \", test['Sentence'][each + 1], \", predict: \", guess, \"(X)\")\n","              totalNum = totalNum + 1\n","\n","          print(\"totalNum: \", totalNum, \" correctNum: \", correctNum, \" accuracy: \", (correctNum/totalNum))\n","\n","      print(\"\")\n","      print(\"Training complete!\")\n","      print(\"\")\n","      print(\"Final result is below!\")\n","      print(final_info)\n","\n","      f.close()\n","\n","      \n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"PostBERT.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"},"widgets":{"application/vnd.jupyter.widget-state+json":{"30fbc7a93f554ba594e8d740635b9f39":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_228d9ee575c348aabc9753a37d69abe0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c90032a3d84145d5ad75d816ee1da433","IPY_MODEL_25254b33b8e54615abe12625b3ca5db0","IPY_MODEL_85bae951a61f4fc58ac3f1222614d75f"]}},"228d9ee575c348aabc9753a37d69abe0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c90032a3d84145d5ad75d816ee1da433":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d9b83dda9f5f42c387d9156f0cb211be","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_390ec10f3ac54218b3324fdfb8c67811"}},"25254b33b8e54615abe12625b3ca5db0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8f294f85bf8d4a998cf2f79277459469","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":371391,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":371391,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e52ffef0d2fa4db38214f148fabc45ca"}},"85bae951a61f4fc58ac3f1222614d75f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_371c1ba8620242b09165208968ebe6d8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 363k/363k [00:00&lt;00:00, 362kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_291f623e7bde4e74a862a58b41ab2e3a"}},"d9b83dda9f5f42c387d9156f0cb211be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"390ec10f3ac54218b3324fdfb8c67811":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8f294f85bf8d4a998cf2f79277459469":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e52ffef0d2fa4db38214f148fabc45ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"371c1ba8620242b09165208968ebe6d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"291f623e7bde4e74a862a58b41ab2e3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3eeec3ac381940cda584e578c3aa8053":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3a4d2fcb89bd48b096545dd0bed177d0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7c619e1ed1b7498f8831d5fedb070f10","IPY_MODEL_ccc5920652d24348958318becddc004a","IPY_MODEL_0b42681294f5433f9af6d6e7201b39a1"]}},"3a4d2fcb89bd48b096545dd0bed177d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7c619e1ed1b7498f8831d5fedb070f10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_56ddccd3e51f4b408edef6306840b050","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5305c73bb46541b3a20cb97616679be7"}},"ccc5920652d24348958318becddc004a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_239a7c59732e4092ba2a3c89cdbeeccc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":77779,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":77779,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ab86f374f9554244a6a1f8ae7fe89b1a"}},"0b42681294f5433f9af6d6e7201b39a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6383a885faac4052a82a5c4638217588","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 76.0k/76.0k [00:00&lt;00:00, 130kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c725b4ceabef41008923d7210e718320"}},"56ddccd3e51f4b408edef6306840b050":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5305c73bb46541b3a20cb97616679be7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"239a7c59732e4092ba2a3c89cdbeeccc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ab86f374f9554244a6a1f8ae7fe89b1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6383a885faac4052a82a5c4638217588":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c725b4ceabef41008923d7210e718320":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"12f83dd5043e4fb088d92da4b97b444b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3059278d7fd446c3aa9ea4141046f523","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fa3d861e6dbf4318bf4a63abbf4b590a","IPY_MODEL_6b1376a9ffca406596ae9570fdbdb79d","IPY_MODEL_eb1b620f9a2f4df09c650a1af4df32a0"]}},"3059278d7fd446c3aa9ea4141046f523":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fa3d861e6dbf4318bf4a63abbf4b590a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_00088c4c0ee347ba9e2b9f7997b01e56","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ff8ef43eb4f4cf8ad1e7a777084f79e"}},"6b1376a9ffca406596ae9570fdbdb79d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d66b9bec27f546ecbcae9b4d89a4cf2c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":51,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":51,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6455b78a8af34272a5702ed15ed81569"}},"eb1b620f9a2f4df09c650a1af4df32a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6033356b8e8d4f40bcfc8320a3ea589d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 51.0/51.0 [00:00&lt;00:00, 2.16kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba20d45f277a48a49e353c3f401f51a5"}},"00088c4c0ee347ba9e2b9f7997b01e56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4ff8ef43eb4f4cf8ad1e7a777084f79e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d66b9bec27f546ecbcae9b4d89a4cf2c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6455b78a8af34272a5702ed15ed81569":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6033356b8e8d4f40bcfc8320a3ea589d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ba20d45f277a48a49e353c3f401f51a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e1b5c6c3deb44edbf4147c0e8c29894":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_68a61c77d03644db9faf5f86a1979851","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c7346b8a061644c9a28912b6dae8fd99","IPY_MODEL_39f876436ec04bda9d9dcd6e43726d72","IPY_MODEL_1a553add063f45d6845e26fecf8dfc59"]}},"68a61c77d03644db9faf5f86a1979851":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c7346b8a061644c9a28912b6dae8fd99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_039df66e866a4c0daceae25169449e5a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_07f2a8af595443828c3fa0a0ea1f33a2"}},"39f876436ec04bda9d9dcd6e43726d72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b4dff72439014576a4e5077e05f028d6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":426,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":426,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ea3b02ba059a4b0ca897eb0242d09c0e"}},"1a553add063f45d6845e26fecf8dfc59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_33c567e74f8e4559b185ca9e00c01a29","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 426/426 [00:00&lt;00:00, 15.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0dc71c95dc5f475780e8e692ab3e88b1"}},"039df66e866a4c0daceae25169449e5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"07f2a8af595443828c3fa0a0ea1f33a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4dff72439014576a4e5077e05f028d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ea3b02ba059a4b0ca897eb0242d09c0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33c567e74f8e4559b185ca9e00c01a29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0dc71c95dc5f475780e8e692ab3e88b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78f8a405b01f4212b6eb22054cfa1f51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c89f043a3b8f4e0898db7dd883dc345f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d1c06796bc8947279a7ff70b5c4d0dbf","IPY_MODEL_022e6d92b11445719d08edfee49cb1a2","IPY_MODEL_15ef21b1cb474c97be0d596776aa0875"]}},"c89f043a3b8f4e0898db7dd883dc345f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1c06796bc8947279a7ff70b5c4d0dbf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_748b420820f24ef58f19351cf191b0cf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2adb514e62974f9bbb77f20ba2dae2dc"}},"022e6d92b11445719d08edfee49cb1a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_80b1ed78d5404801b26e6417255b390b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":368792146,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":368792146,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db48d87d975d4e40a15c58d468db2ddc"}},"15ef21b1cb474c97be0d596776aa0875":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9139268762be4e27bbd90889ecc7302c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 352M/352M [00:13&lt;00:00, 29.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b364367ba21743aa9cc8b053414c0d6d"}},"748b420820f24ef58f19351cf191b0cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2adb514e62974f9bbb77f20ba2dae2dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"80b1ed78d5404801b26e6417255b390b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"db48d87d975d4e40a15c58d468db2ddc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9139268762be4e27bbd90889ecc7302c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b364367ba21743aa9cc8b053414c0d6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}