{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"PostGPT-2.ipynb","provenance":[],"machine_shape":"hm","collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0b8c008edeab4c9d85f87aa026e75593":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f87e055384fd412da192df3a72312a71","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_144a6920cff6430facf747f209bac758","IPY_MODEL_cb1e5614c9314f719188d71f84051fe2","IPY_MODEL_8d6e26e9aeb44c0596bed3710e6295bf"]}},"f87e055384fd412da192df3a72312a71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"144a6920cff6430facf747f209bac758":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4a197ab5533940f3bdc3049d63486e5b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_631f9e0377dc4369b9c4b18a2fcaa99d"}},"cb1e5614c9314f719188d71f84051fe2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_37a7a6e63b0f4035bccf52b2bbb3edbe","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_09d49d47957d4daa9d21e93b18e3abb7"}},"8d6e26e9aeb44c0596bed3710e6295bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cbab2aa7d85a48ce8eef42ee428a4d23","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.98k/0.98k [00:00&lt;00:00, 32.3kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2363c30610d64bae8c01fa3c22be9c52"}},"4a197ab5533940f3bdc3049d63486e5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"631f9e0377dc4369b9c4b18a2fcaa99d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"37a7a6e63b0f4035bccf52b2bbb3edbe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"09d49d47957d4daa9d21e93b18e3abb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cbab2aa7d85a48ce8eef42ee428a4d23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2363c30610d64bae8c01fa3c22be9c52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"790155fdc85b454b8b1d0f9cb8f1f1db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6617856cb56b45638474b43af4b2c251","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2665c8092ce94310a0b8eb488c6db168","IPY_MODEL_1f6ecaed94c944fc83c5c33168b89615","IPY_MODEL_555065cf529a4f779bf9c2c4b00af167"]}},"6617856cb56b45638474b43af4b2c251":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2665c8092ce94310a0b8eb488c6db168":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c6ce66fda42e40c8a14b4bafab198d37","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0cb9e0a2aa0845e68a541a5ae03bc224"}},"1f6ecaed94c944fc83c5c33168b89615":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_34c66303e08d423fad969031f03e9009","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":513302779,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":513302779,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cf747c2aa7c0422bb45b6f02a2bf0f57"}},"555065cf529a4f779bf9c2c4b00af167":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fbb4221823af4c4fba027b0d20e2b24d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 490M/490M [00:12&lt;00:00, 43.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f745b37f95f84482bba7e2018ee8b91d"}},"c6ce66fda42e40c8a14b4bafab198d37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0cb9e0a2aa0845e68a541a5ae03bc224":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"34c66303e08d423fad969031f03e9009":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cf747c2aa7c0422bb45b6f02a2bf0f57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fbb4221823af4c4fba027b0d20e2b24d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f745b37f95f84482bba7e2018ee8b91d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"384ddeb7da874916a0aee5624887807f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3dc57ae02c224f29be5d63702a376038","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bb72873b32ca4b74a1c0b5165d2c95c5","IPY_MODEL_a67cf2968f34411786241c399cd7b118","IPY_MODEL_0d53c27f1c9147c49c78f95f594dcb26"]}},"3dc57ae02c224f29be5d63702a376038":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb72873b32ca4b74a1c0b5165d2c95c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_74aef30ea96948708ee0d7c6a23b21c0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_30173b3330004974a74241bf7506a7c8"}},"a67cf2968f34411786241c399cd7b118":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b5cb1dbaa35943f5b63fa355769b1797","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2825034,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2825034,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d402b29a5bea4b90af0240df4ebac8bc"}},"0d53c27f1c9147c49c78f95f594dcb26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2a6ae28e335641ba887d10e89cecb396","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.69M/2.69M [00:00&lt;00:00, 2.79MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dddede35a61f4fbfbc2c82f67df628bd"}},"74aef30ea96948708ee0d7c6a23b21c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"30173b3330004974a74241bf7506a7c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5cb1dbaa35943f5b63fa355769b1797":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d402b29a5bea4b90af0240df4ebac8bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2a6ae28e335641ba887d10e89cecb396":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dddede35a61f4fbfbc2c82f67df628bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"cFEpHz9q2TkF"},"source":["# PostGPT-2\n","https://www.kaggle.com/baekseungyun/gpt-2-with-huggingface-pytorch<br>"]},{"cell_type":"code","metadata":{"id":"li9QWpubgHQ4"},"source":["##Parameter setting\n","setEpoch = 51\n","setLearningRate = 0.00002\n","setEpsilon = 1e-8\n","setBatch = 16\n","setMaxLength = 128\n","setSeed = 42\n","setTry = 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LAZ1CSc3Bm_","executionInfo":{"status":"ok","timestamp":1640777417222,"user_tz":-540,"elapsed":21324,"user":{"displayName":"Seongmin Mun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxXPWH0f2f0ThPPwM2evOCWKaCSlwmGiaeEFSK=s64","userId":"17295717412647902050"}},"outputId":"55a077b7-79ac-48d8-fa4d-aa42a0120e89"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')\n","    \n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEAoJWbt2TkL","executionInfo":{"status":"ok","timestamp":1640777434736,"user_tz":-540,"elapsed":15369,"user":{"displayName":"Seongmin Mun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxXPWH0f2f0ThPPwM2evOCWKaCSlwmGiaeEFSK=s64","userId":"17295717412647902050"}},"outputId":"cecd2879-e98e-4db6-f82f-bc9f87a50a8d"},"source":["!pip install transformers\n","!pip install tensorflow\n","!pip install keras"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 9.6 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 53.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 448 kB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 57.8 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 45.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n"]}]},{"cell_type":"code","metadata":{"id":"Hv2_wH8A2TkN"},"source":["import tensorflow as tf\n","import torch\n","import os\n","import pandas as pd\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader, random_split\n","\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from transformers import set_seed, GPT2LMHeadModel, PreTrainedTokenizerFast, GPT2ForSequenceClassification, GPT2Config\n","from transformers import AdamW, get_cosine_schedule_with_warmup\n","\n","import numpy as np\n","import random\n","import time\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X3aCo4t22ahB","executionInfo":{"status":"ok","timestamp":1640777462639,"user_tz":-540,"elapsed":16707,"user":{"displayName":"Seongmin Mun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxXPWH0f2f0ThPPwM2evOCWKaCSlwmGiaeEFSK=s64","userId":"17295717412647902050"}},"outputId":"38f5f498-03f3-4ff7-eaf4-90e628d2f1d9"},"source":["# Mount Google Drive to this Notebook instance.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"YzBndqJRK3jS","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0b8c008edeab4c9d85f87aa026e75593","f87e055384fd412da192df3a72312a71","144a6920cff6430facf747f209bac758","cb1e5614c9314f719188d71f84051fe2","8d6e26e9aeb44c0596bed3710e6295bf","4a197ab5533940f3bdc3049d63486e5b","631f9e0377dc4369b9c4b18a2fcaa99d","37a7a6e63b0f4035bccf52b2bbb3edbe","09d49d47957d4daa9d21e93b18e3abb7","cbab2aa7d85a48ce8eef42ee428a4d23","2363c30610d64bae8c01fa3c22be9c52","790155fdc85b454b8b1d0f9cb8f1f1db","6617856cb56b45638474b43af4b2c251","2665c8092ce94310a0b8eb488c6db168","1f6ecaed94c944fc83c5c33168b89615","555065cf529a4f779bf9c2c4b00af167","c6ce66fda42e40c8a14b4bafab198d37","0cb9e0a2aa0845e68a541a5ae03bc224","34c66303e08d423fad969031f03e9009","cf747c2aa7c0422bb45b6f02a2bf0f57","fbb4221823af4c4fba027b0d20e2b24d","f745b37f95f84482bba7e2018ee8b91d","384ddeb7da874916a0aee5624887807f","3dc57ae02c224f29be5d63702a376038","bb72873b32ca4b74a1c0b5165d2c95c5","a67cf2968f34411786241c399cd7b118","0d53c27f1c9147c49c78f95f594dcb26","74aef30ea96948708ee0d7c6a23b21c0","30173b3330004974a74241bf7506a7c8","b5cb1dbaa35943f5b63fa355769b1797","d402b29a5bea4b90af0240df4ebac8bc","2a6ae28e335641ba887d10e89cecb396","dddede35a61f4fbfbc2c82f67df628bd"],"output_embedded_package_id":"1d6MO6vytPjw2C1dR63tv8crYcyYBGhUs"},"outputId":"be157bbf-0161-427c-ee1b-c8ae773c37f7","executionInfo":{"status":"ok","timestamp":1640780432059,"user_tz":-540,"elapsed":2966640,"user":{"displayName":"Seongmin Mun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxXPWH0f2f0ThPPwM2evOCWKaCSlwmGiaeEFSK=s64","userId":"17295717412647902050"}}},"source":["for currentTry in range(1,setTry):\n","  postpositions = [\"Eyse\",\"Ey\",\"Lo\"] \n","  labelNumber = 0\n","  \n","  for postposition in postpositions:\n","\n","    if postposition == \"Lo\":#6\n","      labelNumber = 6\n","\n","      def outreault(guess):\n","        guess = int(guess)\n","        outFunction = \"\"\n","        if guess == 0:\n","          outFunction = \"FNS\"\n","        elif guess == 1:\n","          outFunction = \"INS\"\n","        elif guess == 2:\n","          outFunction = \"DIR\"\n","        elif guess == 3:\n","          outFunction = \"EFF\"\n","        elif guess == 4:\n","          outFunction = \"CRT\"\n","        elif guess == 5:\n","          outFunction = \"LOC\"\n","        return outFunction\n","\n","    elif postposition == \"Eyse\":#2\n","      labelNumber = 2\n","\n","      def outreault(guess):\n","        guess = int(guess)\n","        outFunction = \"\"\n","        if guess == 0:\n","          outFunction = \"SRC\"\n","        elif guess == 1:\n","          outFunction = \"LOC\"\n","        return outFunction\n","\n","    elif postposition == \"Ey\":#8\n","      labelNumber = 8\n","\n","      def outreault(guess):\n","        guess = int(guess)\n","        outFunction = \"\"\n","        if guess == 0:\n","          outFunction = \"FNS\"\n","        elif guess == 1:\n","          outFunction = \"INS\"\n","        elif guess == 2:\n","          outFunction = \"GOL\"\n","        elif guess == 3:\n","          outFunction = \"EFF\"\n","        elif guess == 4:\n","          outFunction = \"CRT\"\n","        elif guess == 5:\n","          outFunction = \"LOC\"\n","        elif guess == 6:\n","          outFunction = \"AGT\"\n","        elif guess == 7:\n","          outFunction = \"THM\"\n","        return outFunction\n","\n","    # 1. Model and Tokenizer\n","    # https://github.com/SKT-AI/KoGPT2\n","    \n","\n","    set_seed(setSeed) \n","\n","    model_config = GPT2Config.from_pretrained('skt/kogpt2-base-v2', num_labels=labelNumber) \n","    model = GPT2ForSequenceClassification.from_pretrained('skt/kogpt2-base-v2', config=model_config)\n","\n","    tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","      bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n","      pad_token='<pad>', mask_token='<mask>') \n","    tokenizer.padding_side = \"left\" # Very Important\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","    model.resize_token_embeddings(len(tokenizer))\n","    model.config.pad_token_id = model.config.eos_token_id\n","\n","\n","\n","    #2. Build Dataset\n","    testFileDir = fileDir = \"drive/My Drive/2022/AdverbialPostpositions/Data/test_\"+postposition+\".csv\"\n","    testFr = open(testFileDir, 'r')\n","    testContents = testFr.readlines()\n","    testFr.close()\n","\n","    test = pd.DataFrame(columns=('Sentence','Label'))\n","    i = 0\n","\n","    for content in testContents:\n","        if i == 0:\n","            pass\n","        else:\n","            infos = content.split(\",\")\n","            label = int(infos[1])\n","            sentence = infos[2].replace(\"\\n\", \"\")\n","            test.loc[i] = [sentence, label]\n","        i = i + 1\n","\n","    test['Sentence'] = test['Sentence'].str.replace(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', \" \", regex=True)\n","    test['Sentence'] = test['Sentence'].str.replace(r'\\t+', \" \", regex=True)\n","    test['Sentence'] = test['Sentence'].str.replace(r'[\\\\n]+',\" \", regex=True)\n","    test['Sentence'] = test['Sentence'].str.replace(r'[\\s]+', \" \", regex=True)\n","    test['Sentence'] = test['Sentence'].str.strip()\n","\n","    # 분류 추출\n","    test_labels = test['Label']\n","    # 문장 추출\n","    testSentences = test['Sentence']\n","\n","    print(len(testSentences))\n","\n","    fileDir = \"drive/My Drive/2022/AdverbialPostpositions/Data/train_\"+postposition+\".csv\"\n","    fr = open(fileDir, 'r')\n","    contents= fr.readlines()\n","    fr.close()\n","\n","    train = pd.DataFrame(columns=('index', 'Label', 'Sentence'))\n","    i = 0\n","    index = \"\"\n","    label = \"\"\n","    sentence = \"\"\n","    for content in contents:\n","        if i == 0:\n","            pass\n","        else:\n","            infos = content.split(\",\")\n","            index = infos[0]\n","            label = int(infos[1])\n","            sentence = infos[2].replace(\"\\n\",\"\")\n","            train.loc[i] = [index, label, sentence]\n","        i = i + 1\n","\n","\n","    #정제하기\n","\n","    train['Sentence'] = train['Sentence'].str.replace(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》\\\\n\\t]+', \" \", regex=True)\n","    train['Sentence'] = train['Sentence'].str.replace(r'\\t+', \" \", regex=True)\n","    train['Sentence'] = train['Sentence'].str.replace(r'[\\\\n]+',\" \", regex=True)\n","    train['Sentence'] = train['Sentence'].str.replace(r'[\\s]+', \" \", regex=True)\n","    train['Sentence'] = train['Sentence'].str.strip()\n","\n","\n","    class Dataset(Dataset):\n","        def __init__(self, trainData, testData, checked):\n","            self.checked = checked\n","\n","            if self.checked==True:\n","              self.data = trainData\n","            else:\n","              self.data = testData\n","            # self.data = pd.read_csv(os.path.join(\"drive/My Drive/2022/AdverbialPostpositions/Data/\", \"train_\"+postposition+\".csv\" if train else \"test_\"+postposition+\".csv\"))\n","        \n","        def __len__(self):\n","            return len(self.data)\n","        \n","        def __getitem__(self, index):\n","            record = self.data.iloc[index]\n","            text = record['Sentence']\n","            if self.checked==True:\n","                return {'Sentence': text, 'label': record['Label']}\n","            else:\n","                return {'Sentence': text, 'label': '0'}\n","\n","    train_dataset = Dataset(train, test, True)\n","    test_dataset = Dataset(train, test, False)\n","\n","\n","    # train_dataset = train\n","    # test_dataset = test\n","\n","    #3. Data Collator\n","    class Gpt2ClassificationCollator(object):\n","        def __init__(self, tokenizer, max_seq_len=None):\n","            self.tokenizer = tokenizer\n","            self.max_seq_len = max_seq_len\n","            \n","            return\n","        \n","        def __call__(self, sequences):\n","            texts = [sequence['Sentence'] for sequence in sequences]\n","            labels = [int(sequence['label']) for sequence in sequences]\n","            inputs = self.tokenizer(text=texts,\n","                                    return_tensors='pt',\n","                                    padding=True,\n","                                    truncation=True,\n","                                    max_length=self.max_seq_len)\n","            inputs.update({'labels': torch.tensor(labels)})\n","            \n","            return inputs\n","\n","    gpt2classificationcollator = Gpt2ClassificationCollator(tokenizer=tokenizer,\n","                                                            max_seq_len=setMaxLength)\n","\n","    #4. DataLoader\n","\n","    train_size = int(len(train_dataset) * 0.8)\n","    val_size = len(train_dataset) - train_size\n","    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","    train_dataloader = DataLoader(dataset=train_dataset,\n","                                  batch_size=setBatch,\n","                                  shuffle=True,\n","                                  collate_fn=gpt2classificationcollator)\n","    val_dataloader = DataLoader(dataset=val_dataset,\n","                                batch_size=setBatch,\n","                                shuffle=False,\n","                                collate_fn=gpt2classificationcollator)\n","    test_dataloader = DataLoader(dataset=test_dataset,\n","                                batch_size=setBatch,\n","                                shuffle=False,\n","                                collate_fn=gpt2classificationcollator)\n","\n","    #5. Optimizer & Lr Scheduler\n","\n","    total_epochs = setEpoch\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","    ]\n","    optimizer = AdamW(optimizer_grouped_parameters,\n","                      lr=setLearningRate,\n","                      eps=setEpsilon)\n","\n","    num_train_steps = len(train_dataloader) * total_epochs\n","    num_warmup_steps = int(num_train_steps * 0.1) \n","\n","    lr_scheduler = get_cosine_schedule_with_warmup(optimizer,\n","                                                  num_warmup_steps=num_warmup_steps,\n","                                                  num_training_steps = num_train_steps)\n","\n","\n","    #6. Train & Validation\n","    import torch\n","\n","    def train(dataloader, optimizer, scheduler, device_):\n","        global model\n","        model.train()\n","        \n","        prediction_labels = []\n","        true_labels = []\n","        \n","        total_loss = []\n","        \n","        for batch in dataloader:\n","            true_labels += batch['labels'].numpy().flatten().tolist()\n","            batch = {k:v.type(torch.long).to(device_) for k, v in batch.items()}\n","            \n","            \n","            outputs = model(**batch)\n","            loss, logits = outputs[:2]\n","            logits = logits.detach().cpu().numpy()\n","            total_loss.append(loss.item())\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # prevent exploding gradient\n","\n","            optimizer.step()\n","            scheduler.step()\n","            \n","            prediction_labels += logits.argmax(axis=-1).flatten().tolist()\n","        \n","        return true_labels, prediction_labels, total_loss \n","\n","    def validation(dataloader, device_):\n","        global model\n","        model.eval()\n","        \n","        prediction_labels = []\n","        true_labels = []\n","\n","        embedding_outputs = []\n","        \n","        total_loss = []\n","\n","        outputs = []\n","        \n","        for batch in dataloader:\n","            true_labels += batch['labels'].numpy().flatten().tolist()\n","            batch = {k:v.type(torch.long).to(device_) for k, v in batch.items()}\n","            \n","            with torch.no_grad():\n","                outputs = model(**batch)\n","                loss, logits = outputs[:2]\n","                logits = logits.detach().cpu().numpy()\n","                total_loss.append(loss.item())\n","\n","                prediction_labels += logits.argmax(axis=-1).flatten().tolist()\n","\n","                embedding_outputs += logits.tolist()\n","\n","                outputs = outputs\n","            \n","        return true_labels, prediction_labels, total_loss, outputs, embedding_outputs\n","\n","\n","    #7. Run\n","\n","    f = open(\"drive/My Drive/2022/AdverbialPostpositions/Output/GPT2/\"+postposition+\"/Outcomes/\"+postposition+\"_accuracy_trial_\"+str(currentTry)+\"_epoch_\"+str(setEpoch)+\".txt\", 'w')\n","    f.write(\"epoch,sentence,originalLabel,predictedLabel,predictedFunction,result\"+\"\\n\")\n","\n","    from sklearn.metrics import classification_report, accuracy_score\n","\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    model.to(device)\n","\n","    all_loss = {'train_loss': [], 'val_loss': []}\n","    all_acc = {'train_acc': [], 'val_acc': []}\n","    outputs = []\n","\n","    for epoch in range(total_epochs):\n","        y, y_pred, train_loss = train(train_dataloader, optimizer, lr_scheduler, device)\n","        train_acc = accuracy_score(y, y_pred)\n","        \n","        y, y_pred, val_loss, outputs, logits_labels = validation(val_dataloader, device)\n","        val_acc = accuracy_score(y, y_pred)\n","        \n","        all_loss['train_loss'] += train_loss\n","        all_loss['val_loss'] += val_loss\n","        \n","        all_acc['train_acc'].append(train_acc)\n","        all_acc['val_acc'].append(val_acc)\n","\n","        outputs = outputs\n","\n","        print(\"\")\n","        print('======== Epoch {:} / {:} ========'.format(epoch + 1, total_epochs))\n","        print('Training...')\n","        \n","        print(f'Epoch: {epoch}, train_loss: {torch.tensor(train_loss).mean():.3f}, train_acc: {train_acc:.3f}, val_loss: {torch.tensor(val_loss).mean():.3f}, val_acc: {val_acc:.3f}') \n","\n","        y, y_pred, val_loss, outputs, logits_labels = validation(test_dataloader, device)\n","\n","        # print(\"y\",y)\n","        print(\"y_pred\",y_pred)\n","        print(\"y_pred\",len(y_pred))\n","        print(\"logits_labels\",logits_labels)\n","        print(\"logits_labels\",len(logits_labels))\n","        print(\"logits_labels\",len(logits_labels[0]))\n","\n","        sentence_array = []\n","        for i in range(0,len(test['Sentence'])):\n","          each_array = []\n","          for j in range(0,len(logits_labels[i])):\n","            each_array.append(float(logits_labels[i][j]))\n","          sentence_array.append(each_array)\n","\n","        initial_df = pd.DataFrame(sentence_array)\n","\n","        print(\"sentence_array\",sentence_array)\n","\n","        # print(len(sentence_array)) # 479\n","        # print(len(sentence_array[0])) # 37\n","        \n","        from sklearn.manifold import TSNE\n","        tsne = TSNE(n_components=2, random_state=0)\n","        tsne_obj= tsne.fit_transform(initial_df)\n","\n","        tsne_df = pd.DataFrame({'X':tsne_obj[:,0],'Y':tsne_obj[:,1],'Label':test_labels})\n","\n","        tsne_df.to_csv(\"drive/My Drive/2022/AdverbialPostpositions/Output/GPT2/\"+postposition+\"/t-SNE/\"+postposition+\"_tSNE_trial_\"+str(currentTry)+\"_epoch_\"+str(epoch)+\".csv\")\n","\n","        import numpy as np   \n","        import pandas as pd \n","        from plotnine import *\n","\n","        print(\"\")\n","        print(\"  Network visualization  \")\n","        print(ggplot(tsne_df, aes(x='X', y='Y')) + geom_point(aes(colour = 'Label')))\n","\n","\n","        totalNum = 0\n","        correctNum = 0\n","        for each in range(0, len(testSentences)):\n","            # print(test['Label'][each + 1], test['Sentence'][each + 1])\n","            # print(\"y_pred\", len(y_pred))\n","            guess = str(y_pred[each])\n","            if guess == str(test['Label'][each + 1]):\n","                # print(\"input: \", test['Sentence'][each + 1], \", predict: \", guess, \"(O)\")\n","                f.write(str(epoch+1) + \",\" + test['Sentence'][each + 1] + \",\" + str(test['Label'][each + 1]) + \",\" + guess + \",\" + outreault(guess)+ \",1\" + \"\\n\")\n","                correctNum = correctNum + 1\n","            else:\n","                f.write(str(epoch+1) + \",\" + test['Sentence'][each + 1] + \",\" + str(test['Label'][each + 1]) + \",\" + guess + \",\" + outreault(guess) + \",0\" + \"\\n\")       \n","                # print(\"input: \", test['Sentence'][each + 1], \", predict: \", guess, \"(X)\")\n","            totalNum = totalNum + 1\n","\n","        print(\"totalNum: \", totalNum, \" correctNum: \", correctNum, \" accuracy: \", (correctNum/totalNum))\n","\n","    f.close()\n","\n","    print(\"\")\n","    print(\"Training complete!\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}